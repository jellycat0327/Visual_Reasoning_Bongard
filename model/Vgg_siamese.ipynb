{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D,GlobalAveragePooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import numpy.random as rng\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def W_init(shape,name=None):\n",
    "    \"\"\"Initialize weights as in paper\"\"\"\n",
    "    values = rng.normal(loc=0,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)\n",
    "#//TODO: figure out how to initialize layer biases in keras.\n",
    "def b_init(shape,name=None):\n",
    "    \"\"\"Initialize bias as in paper\"\"\"\n",
    "    values=rng.normal(loc=0.5,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (105, 105, 3)\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "vgg16_model = VGG16(weights = 'imagenet', include_top = False)\n",
    "x = vgg16_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(4096,activation=\"sigmoid\",kernel_regularizer=l2(1e-3),kernel_initializer=W_init,bias_initializer=b_init)(x)\n",
    "convnet=Model(input = vgg16_model.input, output = predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              2101248   \n",
      "=================================================================\n",
      "Total params: 16,815,936\n",
      "Trainable params: 16,815,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "convnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16820033"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the convnet Sequential model on each of the input tensors so params will be shared\n",
    "encoded_l = convnet(left_input)\n",
    "encoded_r = convnet(right_input)\n",
    "#layer to merge two encoded inputs with the l1 distance between them\n",
    "L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "#call this layer on list of two input tensors.\n",
    "L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "prediction = Dense(1,activation='sigmoid',bias_initializer=b_init)(L1_distance)\n",
    "siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "\n",
    "optimizer = Adam(0.00006)\n",
    "#//TODO: get layerwise learning rates and momentum annealing scheme described in paperworking\n",
    "siamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer)\n",
    "\n",
    "siamese_net.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 105, 105, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 105, 105, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 4096)         16815936    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4096)         0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            4097        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 16,820,033\n",
      "Trainable params: 16,820,033\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all layers of the pre-trained model\n",
    "for layer in vgg16_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 105, 105, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 105, 105, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 4096)         16815936    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4096)         0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            4097        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 31,534,721\n",
      "Trainable params: 16,820,033\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:975: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "siamese_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training alphabets\n",
      "dict_keys(['right', 'left'])\n",
      "validation alphabets:\n",
      "dict_keys(['right', 'left'])\n"
     ]
    }
   ],
   "source": [
    "PATH = \"./Bongard/BP_61\" #CHANGE THIS - path where the pickled data is stored\n",
    "\n",
    "with open(os.path.join(PATH, \"train.pickle\"), \"rb\") as f:\n",
    "    (X,c) = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(PATH, \"val.pickle\"), \"rb\") as f:\n",
    "    (Xval,cval) = pickle.load(f)\n",
    "    \n",
    "print(\"training alphabets\")\n",
    "print(c.keys())\n",
    "print(\"validation alphabets:\")\n",
    "print(cval.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ./Bongard/BP_61/train.pickle\n",
      "loading data from ./Bongard/BP_61/val.pickle\n"
     ]
    }
   ],
   "source": [
    "class Siamese_Loader:\n",
    "    \"\"\"For loading batches and testing tasks to a siamese net\"\"\"\n",
    "    def __init__(self, path, data_subsets = [\"train\", \"val\"]):\n",
    "        self.data = {}\n",
    "        self.categories = {}\n",
    "        self.info = {}\n",
    "        \n",
    "        for name in data_subsets:\n",
    "            file_path = os.path.join(path, name + \".pickle\")\n",
    "            print(\"loading data from {}\".format(file_path))\n",
    "            with open(file_path,\"rb\") as f:\n",
    "                (X,c) = pickle.load(f)\n",
    "                self.data[name] = X\n",
    "                self.categories[name] = c\n",
    "\n",
    "    def get_batch(self,batch_size,s=\"train\"):\n",
    "        \"\"\"Create batch of n pairs, half same class, half different class\"\"\"\n",
    "        X=self.data[s]\n",
    "        n_classes, n_examples, w, h = X.shape\n",
    "\n",
    "        #randomly sample several classes to use in the batch\n",
    "        categories = rng.choice(n_classes,size=(batch_size,),replace=False)\n",
    "        #initialize 2 empty arrays for the input image batch\n",
    "        #pairs=[np.zeros((batch_size, h, w,1)) for i in range(2)]\n",
    "        pairs=[np.zeros((batch_size, h, w,3)) for i in range(2)]\n",
    "        #initialize vector for the targets, and make one half of it '1's, so 2nd half of batch has same class\n",
    "        targets=np.zeros((batch_size,))\n",
    "        targets[batch_size//2:] = 1\n",
    "        for i in range(batch_size):\n",
    "            category = categories[i]\n",
    "            idx_1 = rng.randint(0, n_examples)\n",
    "            #pairs[0][i,:,:,:] = X[category, idx_1].reshape(w, h, 1)\n",
    "            \n",
    "            pairs[0][i,:,:,:] = cv2.cvtColor(cv2.resize(X[category, idx_1], (w, h)), cv2.COLOR_GRAY2RGB)\n",
    "            idx_2 = rng.randint(0, n_examples)\n",
    "            #pick images of same class for 1st half, different for 2nd\n",
    "            if i >= batch_size // 2:\n",
    "                category_2 = category  \n",
    "            else: \n",
    "                #add a random number to the category modulo n classes to ensure 2nd image has\n",
    "                # ..different category\n",
    "                category_2 = (category + rng.randint(1,n_classes)) % n_classes\n",
    "            #pairs[1][i,:,:,:] = X[category_2,idx_2].reshape(w, h,1)\n",
    "            pairs[1][i,:,:,:]=cv2.cvtColor(cv2.resize(X[category_2,idx_2], (w, h)), cv2.COLOR_GRAY2RGB)\n",
    "        return pairs, targets\n",
    "    \n",
    "    def generate(self, batch_size, s=\"train\"):\n",
    "        \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
    "        while True:\n",
    "            pairs, targets = self.get_batch(batch_size,s)\n",
    "            yield (pairs, targets)   \n",
    "            \n",
    "    def test_bongard(self,model,N,k,s='val',s1='train',verbose=0):\n",
    "        \n",
    "        X_train=self.data[s1]\n",
    "        X_val=self.data[s]\n",
    "        \n",
    "        n_classes, n_examples, w, h = X_train.shape\n",
    "        m = n_classes*n_examples\n",
    "        X_train=X_train.reshape(m, w, h,1)\n",
    "        X_train = [cv2.cvtColor(cv2.resize(i, (w, h)), cv2.COLOR_GRAY2RGB) for i in X_train]\n",
    "        X_train=np.array(X_train)\n",
    "\n",
    "        \n",
    "        n_classes_val, n_examples_val, w, h = X_val.shape\n",
    "        m_val = n_classes_val * n_examples_val\n",
    "        X_val=X_val.reshape(m_val, w, h,1)\n",
    "        X_val = [cv2.cvtColor(cv2.resize(i, (w, h)), cv2.COLOR_GRAY2RGB) for i in X_val]\n",
    "        X_val=np.array(X_val)\n",
    "        \n",
    "        \n",
    "        n_correct = 0\n",
    "        \n",
    "        for i in range(k):\n",
    "            \n",
    "            test_image = np.asarray([X_val[i,:,:,:]]*m).reshape(m, w, h,3)\n",
    "            support_set =  X_train\n",
    "            if i < k/2:\n",
    "                targets=0\n",
    "            else:\n",
    "                targets=1 \n",
    "            \n",
    "            pairs = [test_image,support_set]\n",
    "            \n",
    "            probs = model.predict(pairs)\n",
    "            if np.argmax(probs)<6:\n",
    "                test_result=0\n",
    "            else:\n",
    "                test_result=1\n",
    "            if test_result== targets:\n",
    "                n_correct+=1\n",
    "                \n",
    "        percent_correct = (100.0*n_correct / k)\n",
    "        if verbose:\n",
    "            print(\"Got an average of {}% {} way one-shot learning accuracy\".format(percent_correct,N))\n",
    "        return percent_correct\n",
    "            \n",
    "    def train(self, model, epochs, verbosity):\n",
    "        model.fit_generator(self.generate(batch_size),\n",
    "                            \n",
    "                             )\n",
    "    \n",
    "    \n",
    "#Instantiate the class\n",
    "loader = Siamese_Loader(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:975: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95217305\n",
      "0.8802153\n",
      "0.9425515\n",
      "0.8230851\n",
      "0.7964079\n",
      "0.88215125\n",
      "0.7999219\n",
      "1.0337662\n",
      "0.639658\n",
      "0.60193086\n",
      "1.1992917\n",
      "1.0023569\n",
      "0.91177136\n",
      "1.0685813\n",
      "0.8904298\n",
      "1.0115752\n",
      "0.83753735\n",
      "0.98123217\n",
      "0.8482621\n",
      "0.84103376\n",
      "0.95719457\n",
      "1.02994\n",
      "0.96457887\n",
      "0.93035066\n",
      "0.80721533\n",
      "1.0187571\n",
      "0.86566377\n",
      "1.0011265\n",
      "0.89179754\n",
      "0.8713036\n",
      "0.8522986\n",
      "0.98920023\n",
      "0.8146583\n",
      "0.73497164\n",
      "0.8704916\n",
      "0.9358196\n",
      "0.6520942\n",
      "0.64870787\n",
      "0.90088105\n",
      "0.7417245\n",
      "0.55683106\n",
      "1.288465\n",
      "0.5711302\n",
      "0.49326605\n",
      "1.2889993\n",
      "0.94445956\n",
      "0.8574864\n",
      "0.94398504\n",
      "1.0775361\n",
      "0.98389125\n",
      "iteration 50, training loss: 0.98,\n",
      "0.8932611\n",
      "0.8824159\n",
      "0.891732\n",
      "0.9240705\n",
      "0.8136416\n",
      "0.88514715\n",
      "0.81870615\n",
      "0.81858313\n",
      "0.92680913\n",
      "0.7480073\n",
      "0.935487\n",
      "0.7215479\n",
      "0.84435326\n",
      "0.84233356\n",
      "0.8613289\n",
      "0.77955526\n",
      "0.7826294\n",
      "0.86713094\n",
      "0.7525333\n",
      "1.0460972\n",
      "0.7719383\n",
      "0.6912103\n",
      "0.7907069\n",
      "0.80094755\n",
      "0.91547805\n",
      "0.6857964\n",
      "1.0336889\n",
      "0.86798626\n",
      "0.8410957\n",
      "0.8686414\n",
      "0.83488137\n",
      "0.8206063\n",
      "0.7978583\n",
      "0.79293996\n",
      "0.7868351\n",
      "0.92702115\n",
      "0.94301176\n",
      "0.8474517\n",
      "0.8468558\n",
      "0.89966863\n",
      "0.82711667\n",
      "0.93254554\n",
      "0.6801464\n",
      "0.6768384\n",
      "0.7339619\n",
      "0.7455003\n",
      "0.6594031\n",
      "1.0443995\n",
      "0.77941424\n",
      "0.8287357\n",
      "iteration 100, training loss: 0.83,\n",
      "0.82855564\n",
      "evaluating\n",
      "Got an average of 53.2% 2 way one-shot learning accuracy\n",
      "saving\n",
      "0.86512196\n",
      "evaluating\n",
      "Got an average of 54.7% 2 way one-shot learning accuracy\n",
      "saving\n",
      "0.7382992\n",
      "evaluating\n",
      "Got an average of 55.5% 2 way one-shot learning accuracy\n",
      "saving\n",
      "0.6674247\n",
      "evaluating\n",
      "Got an average of 60.1% 2 way one-shot learning accuracy\n",
      "saving\n",
      "0.82514834\n",
      "evaluating\n",
      "Got an average of 58.3% 2 way one-shot learning accuracy\n",
      "0.96068364\n",
      "evaluating\n",
      "Got an average of 52.7% 2 way one-shot learning accuracy\n",
      "0.80430007\n",
      "evaluating\n",
      "Got an average of 55.6% 2 way one-shot learning accuracy\n",
      "0.7799077\n",
      "evaluating\n",
      "Got an average of 60.9% 2 way one-shot learning accuracy\n",
      "saving\n",
      "0.8223622\n",
      "evaluating\n",
      "Got an average of 58.3% 2 way one-shot learning accuracy\n",
      "0.80861664\n",
      "evaluating\n",
      "Got an average of 61.1% 2 way one-shot learning accuracy\n",
      "saving\n",
      "0.72544277\n",
      "evaluating\n",
      "Got an average of 59.3% 2 way one-shot learning accuracy\n",
      "0.83938205\n",
      "evaluating\n",
      "Got an average of 58.3% 2 way one-shot learning accuracy\n",
      "0.68011343\n",
      "evaluating\n",
      "Got an average of 57.0% 2 way one-shot learning accuracy\n",
      "0.8016554\n",
      "evaluating\n",
      "Got an average of 58.5% 2 way one-shot learning accuracy\n",
      "0.76517737\n",
      "evaluating\n",
      "Got an average of 58.3% 2 way one-shot learning accuracy\n",
      "0.7763487\n",
      "evaluating\n",
      "Got an average of 57.0% 2 way one-shot learning accuracy\n",
      "0.6745446\n",
      "evaluating\n",
      "Got an average of 58.7% 2 way one-shot learning accuracy\n",
      "1.2005961\n",
      "evaluating\n",
      "Got an average of 57.5% 2 way one-shot learning accuracy\n",
      "0.81341124\n",
      "evaluating\n",
      "Got an average of 55.4% 2 way one-shot learning accuracy\n",
      "0.79381734\n",
      "evaluating\n",
      "Got an average of 54.9% 2 way one-shot learning accuracy\n",
      "0.67963654\n",
      "evaluating\n",
      "Got an average of 55.0% 2 way one-shot learning accuracy\n",
      "0.80810034\n",
      "evaluating\n",
      "Got an average of 56.2% 2 way one-shot learning accuracy\n",
      "0.65085804\n",
      "evaluating\n",
      "Got an average of 57.2% 2 way one-shot learning accuracy\n",
      "0.7454261\n",
      "evaluating\n",
      "Got an average of 58.1% 2 way one-shot learning accuracy\n",
      "0.8134668\n",
      "evaluating\n",
      "Got an average of 58.8% 2 way one-shot learning accuracy\n",
      "0.97287285\n",
      "evaluating\n",
      "Got an average of 60.3% 2 way one-shot learning accuracy\n",
      "0.8988093\n",
      "evaluating\n",
      "Got an average of 57.7% 2 way one-shot learning accuracy\n",
      "0.7651222\n",
      "evaluating\n",
      "Got an average of 59.2% 2 way one-shot learning accuracy\n",
      "1.0328752\n",
      "evaluating\n",
      "Got an average of 55.8% 2 way one-shot learning accuracy\n",
      "0.8342236\n",
      "evaluating\n",
      "Got an average of 55.4% 2 way one-shot learning accuracy\n",
      "0.7889814\n",
      "evaluating\n",
      "Got an average of 55.5% 2 way one-shot learning accuracy\n",
      "0.84404016\n",
      "evaluating\n",
      "Got an average of 52.1% 2 way one-shot learning accuracy\n",
      "0.8784209\n",
      "evaluating\n",
      "Got an average of 47.8% 2 way one-shot learning accuracy\n",
      "0.74728405\n",
      "evaluating\n",
      "Got an average of 46.8% 2 way one-shot learning accuracy\n",
      "1.0391717\n",
      "evaluating\n",
      "Got an average of 54.8% 2 way one-shot learning accuracy\n",
      "0.8913361\n",
      "evaluating\n",
      "Got an average of 56.0% 2 way one-shot learning accuracy\n",
      "0.79108775\n",
      "evaluating\n",
      "Got an average of 54.5% 2 way one-shot learning accuracy\n",
      "0.79382586\n",
      "evaluating\n"
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "print(\"!\")\n",
    "evaluate_every = 1 # interval for evaluating on one-shot tasks\n",
    "loss_every=50 # interval for printing loss (iterations)\n",
    "batch_size = 2\n",
    "n_iter = 200\n",
    "N_way = 2 # how many classes for testing one-shot tasks>\n",
    "n_val = 1000 #how mahy one-shot tasks to validate on?\n",
    "best = 0.9\n",
    "weights_path = os.path.join(PATH, \"weights\")\n",
    "print(\"training\")\n",
    "for i in range(1, n_iter):\n",
    "    (inputs,targets)=loader.get_batch(batch_size)\n",
    "    loss=siamese_net.train_on_batch(inputs,targets)\n",
    "    print(loss)\n",
    "    if i > n_iter/2:\n",
    "        print(\"evaluating\")\n",
    "        val_acc = loader.test_bongard(siamese_net,N_way,n_val,s='val',s1='train',verbose=True)\n",
    "        if val_acc >= best:\n",
    "            print(\"saving\")\n",
    "            siamese_net.save(weights_path)\n",
    "            best=val_acc\n",
    "\n",
    "    if i % loss_every == 0:\n",
    "        print(\"iteration {}, training loss: {:.2f},\".format(i,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"evaluating\")\n",
    "#val_acc = loader.test_bongard(siamese_net,N_way,n_val,s='val',s1='train',verbose=True)\n",
    "#if val_acc >= best:\n",
    "    #print(\"saving\")\n",
    "    #siamese_net.save(weights_path)\n",
    "    #best=val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
